# Importations des biblioth√®ques n√©cessaires
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from io import StringIO # Pour le dataset de fallback

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# --- Configuration de Matplotlib et Seaborn pour des graphiques clairs ---
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (10, 6) # Taille par d√©faut des figures
plt.rcParams['figure.dpi'] = 100       # R√©solution des figures

print("# --- D√©but de l'ex√©cution du script ---")

# --- 1. Chargement et Premi√®re Exploration des Donn√©es ---
print("\n## √âtape 1 : Chargement et Premi√®re Exploration des Donn√©es")

# Tenter de charger le dataset.csv
try:
    df = pd.read_csv("dataset.csv")
    print("Dataset 'dataset.csv' charg√© avec succ√®s.")

except FileNotFoundError:
    print("Le fichier 'dataset.csv' est introuvable.")

print("\n### 1.1. Aper√ßu des 5 premi√®res lignes du DataFrame :")
print(df.head())

print("\n### 1.2. Informations sur les colonnes et les types de donn√©es :")
df.info()

print("\n### 1.3. R√©partition des classes 'ok'/'incomplete_config' (Probabilit√© A Priori) :")
class_counts = df['label'].value_counts(normalize=True)
print(class_counts)

plt.figure(figsize=(7, 5))
sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')
plt.title('1.3. Probabilit√© A Priori des Classes')
plt.xlabel('Classe')
plt.ylabel('Probabilit√©')
plt.ylim(0, 1)
plt.show()
print("**Explication :** Cette visualisation montre la probabilit√© de base qu'une configuration appartienne √† une classe ou l'autre, avant d'analyser ses caract√©ristiques sp√©cifiques. C'est le point de d√©part pour le mod√®le.")


# --- 2. Pr√©paration et Pr√©traitement des Donn√©es ---
print("\n## √âtape 2 : Pr√©paration et Pr√©traitement des Donn√©es")

df_processed = df.copy()

# 2.1. Encodage de la variable cible 'label'
label_encoder = LabelEncoder()
df_processed['label_encoded'] = label_encoder.fit_transform(df_processed['label'])
print(f"Mapping des labels : {list(label_encoder.classes_)} -> {list(label_encoder.transform(label_encoder.classes_))}")

# 2.2. S√©paration des caract√©ristiques (X) et de la variable cible (y)
X = df_processed.drop(['filename', 'label', 'label_encoded'], axis=1)
y = df_processed['label_encoded']
print(f"\n### 2.2. Taille des caract√©ristiques (X) avant One-Hot Encoding : {X.shape}")
print(f"### 2.2. Taille de la variable cible (y) : {y.shape}")

# 2.3. Gestion des variables cat√©gorielles avec One-Hot Encoding
categorical_features = ['vtp_mode']
numerical_features = X.select_dtypes(include=np.number).columns.tolist()

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='passthrough'
)
X_processed = preprocessor.fit_transform(X)

# R√©cup√©rer les noms des caract√©ristiques apr√®s pr√©traitement
one_hot_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)
feature_names_processed = list(one_hot_feature_names) + numerical_features

print("\n### 2.3. Aper√ßu des caract√©ristiques apr√®s pr√©traitement (premi√®re ligne) :")
X_processed_sample_df = pd.DataFrame(X_processed[0:1], columns=feature_names_processed)
print(X_processed_sample_df.T.rename(columns={0: 'Valeur'}))

# 2.4. Division des donn√©es en ensembles d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y)
print(f"\n### 2.4. Taille de l'ensemble d'entra√Ænement (X_train) : {X_train.shape}")
print(f"### 2.4. Taille de l'ensemble de test (X_test) : {X_test.shape}")


# --- 3. Construction et Entra√Ænement du Mod√®le ---
print("\n## √âtape 3 : Construction et Entra√Ænement du Mod√®le")

# 3.1. Initialiser le mod√®le de r√©gression logistique
model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)

# 3.2. Entra√Ænement du mod√®le
model.fit(X_train, y_train)
print("‚úÖ Mod√®le de R√©gression Logistique entra√Æn√© avec succ√®s !")

# 3.3. Affichage des poids (coefficients) et du biais
coefficients = model.coef_[0]
intercept = model.intercept_[0]
print(f"\n### 3.3. Biais (Intercept) du mod√®le : {intercept:.4f}")
print("\n### 3.3. Coefficients (poids) des caract√©ristiques (Top 10) :")
feature_coefs = pd.DataFrame({'Feature': feature_names_processed, 'Coefficient': coefficients})
feature_coefs['Absolute_Coefficient'] = np.abs(feature_coefs['Coefficient'])
feature_coefs_sorted = feature_coefs.sort_values(by='Absolute_Coefficient', ascending=False)
print(feature_coefs_sorted.head(10))


# --- 4. D√©monstration du Calcul des Probabilit√©s pour une Configuration Sp√©cifique ---
print("\n## √âtape 4 : D√©monstration du Calcul des Probabilit√©s pour une Configuration Sp√©cifique")

# 4.1. S√©lection d'une configuration d'exemple
sample_index_in_test = 0
sample_config_X = X_test[sample_index_in_test].reshape(1, -1)

print("\n### 4.1. Caract√©ristiques de la configuration d'exemple :")
sample_config_df = pd.DataFrame(sample_config_X, columns=feature_names_processed)
print(sample_config_df.T.rename(columns={0: 'Valeur'}))

true_label_encoded = y_test[sample_index_in_test]
true_label = label_encoder.inverse_transform([true_label_encoded])[0]
print(f"\n### 4.1. Vraie √©tiquette pour cette configuration : '{true_label}'")

# 4.2. Calcul du Score Logit (z)
z_score = intercept + np.dot(sample_config_X, coefficients)[0]
print(f"\n### 4.2. Calcul du Score Logit (z) :")
print(f"  Biais (Intercept) : {intercept:.4f}")
print(f"  Somme pond√©r√©e des caract√©ristiques : {np.dot(sample_config_X, coefficients)[0]:.4f}")
print(f"  Score Logit (z) : {z_score:.4f}")

# 4.3. Transformation du Score Logit en Probabilit√© (Fonction Sigmo√Øde)
prob_ok_calculated = 1 / (1 + np.exp(-z_score))
prob_incomplete_calculated = 1 - prob_ok_calculated
print(f"\n### 4.3. Application de la Fonction Sigmo√Øde :")
print(f"  P(label = 'ok' | Caract√©ristiques) = 1 / (1 + e^(-{z_score:.4f})) = {prob_ok_calculated:.4f}")
print(f"  P(label = 'incomplete_config' | Caract√©ristiques) = 1 - {prob_ok_calculated:.4f} = {prob_incomplete_calculated:.4f}")

model_probabilities = model.predict_proba(sample_config_X)[0]
prob_incomplete_model = model_probabilities[label_encoder.transform(['incomplete_config'])[0]]
prob_ok_model = model_probabilities[label_encoder.transform(['ok'])[0]]
print(f"\n### 4.3. Probabilit√©s obtenues directement du mod√®le (predict_proba) :")
print(f"  P('incomplete_config') du mod√®le : {prob_incomplete_model:.4f}")
print(f"  P('ok') du mod√®le : {prob_ok_model:.4f}")
print(f"  V√©rification : Les probabilit√©s calcul√©es manuellement et par le mod√®le sont tr√®s similaires : {np.isclose(prob_ok_calculated, prob_ok_model)}")

# Visualisation des Probabilit√©s Pr√©dites
probabilities_data = pd.DataFrame({
    'Classe': ['incomplete_config', 'ok'],
    'Probabilit√©': [prob_incomplete_calculated, prob_ok_calculated]
})
plt.figure(figsize=(7, 5))
sns.barplot(x='Classe', y='Probabilit√©', data=probabilities_data, palette='coolwarm')
plt.title(f'4.3. Probabilit√©s Pr√©dites pour la Configuration d\'Exemple (Vraie: {true_label})')
plt.xlabel('Classe')
plt.ylabel('Probabilit√©')
plt.ylim(0, 1)
plt.show()
print("**Explication :** Ce graphique montre la confiance du mod√®le pour chaque classe. Plus la barre est haute, plus la confiance est forte.")

# 4.4. D√©cision de Classification bas√©e sur le Seuil
predicted_class_value = 1 if prob_ok_calculated >= 0.5 else 0
predicted_label = label_encoder.inverse_transform([predicted_class_value])[0]
print(f"\n### 4.4. D√©cision de Classification :")
print(f"  Seuil de d√©cision : 0.5")
print(f"  Probabilit√© de 'ok' : {prob_ok_calculated:.4f}")
print(f"  Pr√©diction finale pour cette configuration : '{predicted_label}'")
print(f"  Le mod√®le a-t-il pr√©dit correctement par rapport √† la vraie √©tiquette ('{true_label}') ? {'Oui' if predicted_label == true_label else 'Non'}")


# --- 5. √âvaluation Globale du Mod√®le ---
print("\n## √âtape 5 : √âvaluation Globale du Mod√®le")

# 5.1. Pr√©diction sur l'ensemble de test
y_pred = model.predict(X_test)

# 5.2. Rapport de Classification
print("\n‚úÖ √âvaluation du mod√®le R√©gression Logistique\n")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# 5.3. Matrice de Confusion
conf_matrix = confusion_matrix(y_test, y_pred)
print("üßÆ Matrice de confusion :\n", conf_matrix)

plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('Pr√©dit')
plt.ylabel('R√©el')
plt.title('5.3. Matrice de Confusion')
plt.show()
print("\n**Interpr√©tation :**")
print("- **True Positives (VP)** : Le mod√®le a pr√©dit 'ok' et c'√©tait 'ok'.")
print("- **True Negatives (VN)** : Le mod√®le a pr√©dit 'incomplete_config' et c'√©tait 'incomplete_config'.")
print("- **False Positives (FP)** : Le mod√®le a pr√©dit 'ok' mais c'√©tait 'incomplete_config' (erreur de Type I).")
print("- **False Negatives (FN)** : Le mod√®le a pr√©dit 'incomplete_config' mais c'√©tait 'ok' (erreur de Type II).")


# --- 6. Interpr√©tation des Coefficients du Mod√®le ---
print("\n## √âtape 6 : Interpr√©tation des Coefficients du Mod√®le")

print("\nüìä Coefficients des features (Top 15 les plus influents) :")
for index, row in feature_coefs_sorted.head(15).iterrows():
    print(f"{row['Feature']:<30} {row['Coefficient']:.4f}")

# Visualisation des coefficients
plt.figure(figsize=(10, 8))
sns.barplot(x='Coefficient', y='Feature', data=feature_coefs_sorted.head(15), palette='coolwarm')
plt.title('6.2. Top 15 des Caract√©ristiques les Plus Influentes')
plt.xlabel('Influence sur la probabilit√© d\'√™tre "ok"')
plt.ylabel('Caract√©ristique')
plt.show()
print("\n**Explication :**")
print("- Les barres vers la droite (coefficients positifs) indiquent que la caract√©ristique augmente la probabilit√© que la config soit 'ok'.")
print("- Les barres vers la gauche (coefficients n√©gatifs) indiquent que la caract√©ristique augmente la probabilit√© que la config soit 'incomplete_config'.")
print("- La longueur de la barre (valeur absolue) montre la force de l'influence.")

print("\n# --- Fin de l'ex√©cution du script ---")